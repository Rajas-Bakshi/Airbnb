{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Airbnb is an online platform that helps individuals connect who wants to rent their homes\n",
    "to the one searching for accommodation. It presently encompasses more than 81,000 cities\n",
    "worldwide and 220 countries. The total number of listings worldwide is about 6 million\n",
    "and actively supports an average of 2 million overnight stays (Zhu, et al., 2020).\n",
    "\n",
    "To captivate more guests , the host has to provide a detailed description of his property.\n",
    "One of the strategies to attract more tenants includes a reasonable price. The star rating\n",
    "system is usually used for determining the cost of the property; currently, there are no clear\n",
    "price recommendations available (Li, et al., 2016; Zhu et al., 2020).\n",
    "\n",
    "\n",
    "## Research Question. \n",
    "\n",
    "This study aims to analyze the Airbnb listing data and find the most relevant features that\n",
    "can be used to suggest an ideal price to the host while listing a new property.\n",
    "\n",
    "## Rationale.\n",
    "\n",
    "In this study, we analyze relation within various features like property type, room type, location to develop a price recommendation model helping hosts decide fair pricing for the property.\n",
    "\n",
    "## Data Description.\n",
    "\n",
    "Publicly available Airbnb data for New York city (Anon., n.d.) has been used for analysis.\n",
    "Variables that are irrelevant to the study has been excluded from the data set. The data set\n",
    "has 59 columns and 36,922 observations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading Dataset from Google Basket. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "text/plain"
   },
   "source": [
    "%sh\n",
    "\n",
    "wget wget https://storage.googleapis.com/big_data_1/listings.csv -O /tmp/listing.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving file to HDFS\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "text/plain"
   },
   "source": [
    "%sh\n",
    "if hdfs dfs -stat /tmp/listing.csv\n",
    "then\n",
    "   hdfs dfs -rm  /tmp/listing.csv\n",
    "fi\n",
    "\n",
    "# Move dataset to hadoop /tmp\n",
    "hdfs dfs -put /tmp/listing.csv /tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField,StringType,IntegerType,StructType, DateType, DoubleType\n",
    "from datetime import datetime as dt\n",
    "from pyspark.sql.functions import isnan, when, count, col, lit\n",
    "import pyspark.sql.functions as f\n",
    "import pyspark.sql.types as t\n",
    "import calendar\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"AirBnb\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and preprocessing\n",
    "Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "\n",
    "df1 = spark.read.format(\"csv\").load(\"/tmp/listing.csv\", header = True)\n",
    "df1.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "for col in df1.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only selecting parameters that are relevant to the study. i.e features that host will enter while listing the property and can be related with price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "\n",
    "df = df1.select(['host_since','price','room_type','bedrooms','host_verifications', 'property_type','latitude', 'longitude','beds','accommodates'])\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only selecting parameters that are relevant to the study. i.e features that host will enter while listing the property and can be related with price.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "df = df.na.drop(subset = ['host_since'])\n",
    "df.select([count(when(isnan(c) | col(c).isNull(), c)). alias(c)for c in df.columns]).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Data type of variables and replacing numm values in bedrooms and bed with mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "\n",
    "df = df.withColumn(\"bedrooms\", df['bedrooms'].cast(IntegerType()))\n",
    "df = df.withColumn(\"beds\", df['beds'].cast(IntegerType()))\n",
    "df = df.withColumn(\"accommodates\", df['accommodates'].cast(IntegerType()))\n",
    "\n",
    "df = df.na.fill(int(df.select(f.mean(df['bedrooms'])).collect()[0][0]),subset = [\"bedrooms\"])\n",
    "df = df.na.fill(int(df.select(f.mean(df['beds'])).collect()[0][0]),subset = [\"beds\"])\n",
    "\n",
    "df = df.withColumn(\"latitude\", df['latitude'].cast(DoubleType())).withColumn(\"longitude\", df['longitude'].cast(DoubleType()))\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing $ symbol from the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "price_new = df.select('price').rdd.map(lambda x:float(x[0].replace('$','').replace(',',''))).map(lambda x: (x,)).toDF().withColumnRenamed('_1','price_new')\n",
    "price_new = price_new.withColumn(\"id\", f.monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Parcing **Host_since** columns as dates, and counting number of varification each host has. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "new_dates = df.select('host_since').rdd.map(lambda x:dt.strptime(x[0], \"%m/%d/%Y\")).map(lambda x: (x, )).toDF().withColumnRenamed('_1', 'new_date')\n",
    "\n",
    "new_host_verifications = df.select('host_verifications').rdd.map(lambda x:x[0].count(\"'\")/2).map(lambda x: (x, )).toDF().withColumnRenamed('_1', 'new_host_verifications')\n",
    "\n",
    "new_dates = new_dates.withColumn(\"id\", f.monotonically_increasing_id())\n",
    "df = df.withColumn(\"id\", f.monotonically_increasing_id())\n",
    "new_host_verifications = new_host_verifications.withColumn(\"id\", f.monotonically_increasing_id())\n",
    "\n",
    "df2 = df.join(new_dates, \"id\", \"outer\").join(new_host_verifications, \"id\", \"outer\").join(price_new, \"id\", \"outer\").orderBy('id').drop('id').drop('host_since').drop('price').drop('host_verifications')\n",
    "\n",
    "df2.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Checking if all the datatypes are as expected or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "df2.createOrReplaceTempView(\"air\")\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the chunk below we group the data by the day of registration \n",
    "and visualize the results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting relations between numbers of registrations on each  month \n",
    "and mean price of property.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.sql\n",
    "\n",
    "Select day(new_date) as day,count(*) as no_of_properties_registered,mean(price_new) as mean_price from air group by day(new_date) order by day(new_date) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.sql\n",
    "\n",
    "Select month(new_date) as month,count(*) as no_of_properties_registered ,mean(price_new) as mean_price from air group by month(new_date) order by month(new_date) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above for counts (Numbers of registrations) is slightly skewed towards right i.e moreproperties have been registered in the second half of the years. However there is no evident effect of months on the price of the property\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No relation can be seen between date and price of property.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting relations between year of registration and number of registrations along with price.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.sql\n",
    "\n",
    "Select year(new_date) as day,count(*) as no_of_properties_registered ,mean(price_new) as mean_price from air group by year(new_date) order by year(new_date) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although, there are more registrations from 2012 to 2017 no significant difference can be seen in the price of the property.\n",
    "Thus, after analyzing the date of registration it shows no significant effect on the price of property.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "\n",
    "df2.groupBy('room_type').agg(f.mean('price_new'),f.count('room_type')).createOrReplaceTempView(\"room_type_count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find out if there exist any relation between room type and price of \n",
    "the property we plot pie chart between room type and mean price for the room type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the types of properties that are majorly \n",
    "listed over the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.sql\n",
    "select * from room_type_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.sql\n",
    "select * from room_type_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing Relation between number of beds and the count of properties along with cost.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.sql\n",
    "\n",
    "Select bedrooms, count(*) as no_of_properties_registered,mean(price_new) as mean_price from air group by bedrooms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.sql\n",
    "Select bedrooms, count(*) as no_of_properties_registered,mean(price_new) as mean_price from air group by bedrooms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "df2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding relation between price and number of people property can accommodates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " let us find the imapct of host verification on the listing of the property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.sql\n",
    "\n",
    "select accommodates, count(*)/10, mean(price_new) from air group by accommodates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.sql\n",
    "\n",
    "select new_host_verifications,sum(price_new) from air group by new_host_verifications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding impact of property type on price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.sql\n",
    "select property_type, mean(price_new) from air group by property_type order by mean(price_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "df2.drop('new_date').select([count(when(isnan(c), c)).alias(c) for c in df2.drop('new_date').columns]).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the above analysis we understand that room and property type plays important and are correlated to the price of the property.\n",
    "Inorder to understand the relation better we calculate the pearson correlation between data. However, some of these features are in string format; to perform further analysis we perform String indexing on these features.\n",
    "The code below is used to String index the above columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"room_type\", outputCol=\"Index_room\")\n",
    "indexed = indexer.fit(df2).transform(df2)\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"property_type\", outputCol=\"Index_property\")\n",
    "indexed = indexer.fit(indexed).transform(indexed)\n",
    "\n",
    "indexed= indexed.select([ 'bedrooms',  'latitude', 'longitude', 'beds', 'accommodates', 'new_host_verifications', 'price_new', 'Index_property','Index_room'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "\n",
    "\n",
    "indexed.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "\n",
    "indexed.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is finally ready to calculate the Pearson Correlation. The code below is used to find the correlation between the data.\n",
    "Once the correlation have been calculated we filter the columns with correlation less than 0.05. The columns are filtered due to following reasons.\n",
    "\n",
    "1.Reduce the dimensions of the data.\n",
    "2.To Pervent over fitting or under fitting of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "\n",
    "corr_list = [(c,indexed.select(f.corr(c,'price_new')).collect()[0][0]) for c in indexed.drop('price_new').columns]\n",
    "\n",
    "deptSchema = StructType([       \n",
    "    StructField('Feature', StringType(), True),\n",
    "    StructField('correlation_with_price', DoubleType(), True)\n",
    "])\n",
    "\n",
    "corr_df = spark.createDataFrame(data=corr_list, schema = deptSchema)\n",
    "\n",
    "\n",
    "corr_df.createOrReplaceTempView('corr_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of correlation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.sql\n",
    "\n",
    "select *  from corr_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keeping the columns with higher corelation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "\n",
    " indexed = indexed.select(['bedrooms', 'longitude', 'beds', 'accommodates', 'price_new', 'Index_property', 'Index_room'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "indexed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing one hot encoding so that we can feed the data to the machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "OHE_encoded = OneHotEncoder(inputCol = 'Index_room', outputCol = 'Index_room_').transform(indexed)\n",
    "OHE_encoded = OneHotEncoder(inputCol = 'Index_property', outputCol = 'Index_property_').transform(OHE_encoded)\n",
    "\n",
    "OHE_encoded.select(['bedrooms', 'longitude', 'beds', 'accommodates', 'price_new','Index_room_','Index_property_'])\n",
    "OHE_encoded.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "Creating dense vector \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols =['bedrooms', 'longitude', 'beds', 'accommodates', 'Index_room_', 'Index_property_'], outputCol = \"features\" )\n",
    "\n",
    "output =assembler.transform(OHE_encoded)\n",
    "\n",
    "output = output.select(['features', 'price_new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "\n",
    "train_data,test_data = output.randomSplit([0.8,0.2])\n",
    "train_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Independent features has a large portion of binary variables, thus Random Forest Regression model is suitable for such applications.\n",
    "The code below splits the data into train and test sets. After splitting, we pass the data to the Random Forest Regression engine with 100 Trees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol='price_new', numTrees = 100)\n",
    "model = rf.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "from pyspark.sql.functions import monotonically_increasing_id \n",
    "\n",
    "predictions = model.transform(test_data)\n",
    "predictions.createOrReplaceTempView('pred')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk of code given below is used to visualize our predictions and give us a better understanding on the performance of our engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.sql\n",
    "\n",
    "Select row_number() over (order by \"price_new\") as num, * from pred limit 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating RSME of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.pyspark3\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"price_new\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    \n",
    "rmse = evaluator.evaluate(predictions.limit(5))\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RSME of the model is 54. However, just RSME is not sufficient to evaluate the model. Thus, the code below is used to calculate the mean of dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%livy2.sql\n",
    "\n",
    "select mean(price_new) from air\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion. \n",
    "\n",
    "Thus, we have successfully extracted features that can be used for recommending prices for a new listing. The date of registration does not play a significant role in determining the cost of the property. However, features such as room type, property type, bedrooms,longitude, number of beds, and the number of people a property can accommodate can be used to recommend a favorable fare.\n",
    "\n",
    "Random Forest Regression engine is used to predict an ideal price rate for the property. The model has an RSME value of 54 and is reasonably suitable for the application. The performance of the recommendation engine can be improved by using complex modeling techniques and tuning hyperparameters.\n",
    "\n",
    "## Improvisation\n",
    "\n",
    "Using automated script to update date in every 15 days. Script is included in the Report.\n",
    "## References\n",
    "\n",
    "Anon., n.d. Inside Airbnb (Get the data). [Online] \n",
    "  Available at: http://insideairbnb.com/get-the-data.html\n",
    "  [Accessed 1 2021].\n",
    "\n",
    "Li, Y., Pan, Q., Yang, T. & Guo, L., 2016. Reasonable Price Recommendation on Airbnb Using Multi-Scale          Clustering. Chengdu, China, TCCT.\n",
    "\n",
    "Zhu, A., Li, R. & Xie, Z., 2020. Machine Learning Prediction of New York Airbnb. Irvine, CA, USA, USA, IEEE.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 2.0.0",
   "language": "python",
   "name": "spark2"
  },
  "language_info": {
   "codemirror_mode": "text/python",
   "file_extension": ".py",
   "mimetype": "text/python",
   "name": "scala",
   "pygments_lexer": "python",
   "version": "3.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
